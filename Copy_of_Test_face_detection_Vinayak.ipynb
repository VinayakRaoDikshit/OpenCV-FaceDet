{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SiGryVaQsnz"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbsSmDeEiMCk"
      },
      "source": [
        "# __Objective:__ Given the input video file, localize and draw bounding boxes around the face of characters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbXUY_Y2XLYu",
        "outputId": "490d7810-6120-49e3-91dd-cad78204ce23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1nyeeqBJyDr2zphBDQ9ruh99JBdYm4nPH\n",
            "To: /content/test_video.m4\n",
            "\r  0% 0.00/7.54M [00:00<?, ?B/s]\r 63% 4.72M/7.54M [00:00<00:00, 28.2MB/s]\r100% 7.54M/7.54M [00:00<00:00, 42.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "#downloading the video file as test_video.mp4\n",
        "! gdown --fuzzy https://drive.google.com/file/d/1nyeeqBJyDr2zphBDQ9ruh99JBdYm4nPH/view?usp=sharing --o test_video.mp4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVG6sk6YtQvQ"
      },
      "source": [
        "### Approach/Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K94MhyPxRZ9L"
      },
      "source": [
        "I am using OpenCV's Cascade classifier linked [here](https://docs.opencv.org/3.4/db/d28/tutorial_cascade_classifier.html)\n",
        "\n",
        "So, for that, importing the open cv library.\n",
        "\n",
        "My approach is as follows:\n",
        "\n",
        "1. Upload the video on Colab\n",
        "2. Convert the video into an Open CV object.\n",
        "3. For each frame of the video:<br>\n",
        "   3.1 Convert it into grayscale.<br>\n",
        "   3.2 The detectMultiScale method of the face_cascade object is used to detect faces in the grayscale frame.<br>\n",
        "   3.3 Draw a rectangle around each detected face in the frame.<br>\n",
        "   3.4 The processed frame is saved into the output_images directory as a jpg image.\n",
        "\n",
        "4. Download the files from the folder output_images. There will be as many files as the number of frames in the video. Downloading multiple files in colab manually is not posssible, so I wrote the code to download them all at once in a zip file. I took some help from google and stackoverflow to achieve this.\n",
        "\n",
        "5. After that on my local system, I used FFmpeg framework to create a video from all the downloaded images (frames). I had to do this locally, as earlier I tried to produce an output video in colab only using OpenCVs videowriter object, however, the video wasn't loading.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJ4GL0V4qWwn"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import cv2\n",
        "import os\n",
        "from zipfile import ZipFile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwWmqyieg0Gj"
      },
      "outputs": [],
      "source": [
        "#Step 1\n",
        "! gdown --fuzzy https://drive.google.com/file/d/1guTg2NijehjIWREaMhS8pz-B8L29VH5A/view?usp=sharing --o test_video.mp4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTPjXcheg39z"
      },
      "outputs": [],
      "source": [
        "#Creating a directory to store the processd images with faces tracked\n",
        "output_dir = \"output_images\"\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHJUGGm8hP8I"
      },
      "outputs": [],
      "source": [
        "#Loading the haar cascade classifier from cv2\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "#Step2\n",
        "video_path = \"test_video.mp4\"\n",
        "video = cv2.VideoCapture(video_path)\n",
        "\n",
        "#Step3\n",
        "while True:\n",
        "    ret, frame = video.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "    for (x, y, w, h) in faces:\n",
        "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "\n",
        "    # Save the processed frame as an image file\n",
        "    frame_number = int(video.get(cv2.CAP_PROP_POS_FRAMES))\n",
        "    image_path = os.path.join(output_dir, f\"frame_{frame_number:04d}.jpg\")\n",
        "    cv2.imwrite(image_path, frame)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWFxJnTTh2J-"
      },
      "outputs": [],
      "source": [
        "#Step 4\n",
        "folder_path = '/content/output_images'\n",
        "\n",
        "# Create a zip file with the folder name\n",
        "zip_filename = os.path.basename(folder_path) + '.zip'\n",
        "with ZipFile(zip_filename, 'w') as zip_file:\n",
        "  for root, _, files in os.walk(folder_path):\n",
        "    for filename in files:\n",
        "      file_path = os.path.join(root, filename)\n",
        "      zip_file.write(file_path, os.path.relpath(file_path, os.path.join(folder_path, '..')))\n",
        "\n",
        "# Download the zip file using Colab files.download\n",
        "from google.colab import files\n",
        "files.download(zip_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAwBC5CAh_Au"
      },
      "source": [
        "For step 5, I used the following code:\n",
        "\n",
        "`ffmpeg -r 30 -f image2 -s 640x480 -i output_images/frame_%04d.jpg -vcodec libx264 -crf 25 -pix_fmt yuv420p output.mp4`\n",
        "\n",
        "The output_images is the folder with all the face detected frames. Here the output video will be of resolution 640*480 with a frame rate of 30 FPS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCpcvISrwmf4",
        "outputId": "de6dc9f4-94f8-4407-a5db-d336d649cda9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Hw-UbixS3GzXc_ThYlY6wf8DLcb5jGxu\n",
            "To: /content/output_video.mp4\n",
            "100% 6.10M/6.10M [00:00<00:00, 12.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "# result video\n",
        "! gdown --fuzzy https://drive.google.com/file/d/1Hw-UbixS3GzXc_ThYlY6wf8DLcb5jGxu/view?usp=sharing --o output_video.mp4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQPlLUKHt9Xp"
      },
      "source": [
        "## FAQs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcsERn4ouB-q"
      },
      "source": [
        "#### About the video processing library and localization model you used?\n",
        "\n",
        "Video processing library: OpenCV <br>\n",
        "Localization model: Pre-trained Haar Cascade classifier for detecting frontal faces (part of OpenCVs object detection models)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rCI5cH1urMp"
      },
      "source": [
        "#### What better approach I might have implemented?\n",
        "\n",
        "Firstly, I would like to increase the accuracy of my current approach. For a better approach I would say that I would create a new object detection model and train it according to the problem statement. However, a better approach would be to use transfer learning upon the currenlty used state of the art CNN models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLVbwOMXuvZZ"
      },
      "source": [
        "####  Explaining some real life use cases of Object detection or localization. \n",
        "\n",
        "\n",
        "1. Attendance monitoring systems: To log the attendance of employees or students by scanning their faces at entry and exit, not directly object detection per se but object recognition.\n",
        "\n",
        "2. Traffic rule monitoring systems: To identify law breaking vehicle owners from their numberplates, the numberplate data can be obtained from CCTV footage of traffic departments.\n",
        "\n",
        "3. Obstacle avoidance in autonomous vehicles: Self driving cars can use object detection systems to classifiy, differentiate and avoid obstacles, other vehicles, or even humans on the road."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
